# Eye & Hand Gesture Mouse Control

## Problem
Traditional input devices limit accessibility and are not suitable for hands-free or touchless environments.

## Solution
A computer visionâ€“based system that uses eye blinks and gaze direction for cursor movement, and hand gestures for clicking, dragging, and scrolling.

## Tech Stack
Python  
OpenCV  
Mediapipe  
PyAutoGUI  

## Approach
- Facial landmarks used to detect eye blinks and gaze direction  
- Hand landmarks mapped to click, drag, and scroll gestures  
- Real-time tracking optimized for low latency  
- Mouse actions controlled through system-level automation  

## Impact
Provides a low-cost, accessible, hands-free interaction method suitable for assistive technology and gesture-driven interfaces.


## Source Code
Coming soon
